(dp0
S'training_loss'
p1
(lp2
F497.7859191894531
aF254.67303466796875
aF257.28533935546875
aF182.73818969726562
aF174.2595977783203
aF173.53604125976562
aF172.6390838623047
aF169.0421142578125
aF171.4662322998047
aF168.48861694335938
aF175.385009765625
aF172.5224609375
aF165.45654296875
aF163.4575958251953
aF161.39329528808594
aF153.49072265625
aF147.84848022460938
aF140.84019470214844
aF130.885009765625
aF117.03429412841797
aF110.6958236694336
aF106.66307830810547
aF115.86338806152344
aF105.30384063720703
aF94.3990707397461
aF106.74349975585938
aF95.8139419555664
aF89.89309692382812
aF90.27971649169922
aF89.62217712402344
aF84.2013168334961
asS'validation_loss'
p3
(lp4
F482.0155334472656
aF248.78317260742188
aF250.5345916748047
aF177.17333984375
aF168.40484619140625
aF169.5028839111328
aF164.15582275390625
aF160.5686492919922
aF162.1510772705078
aF161.2399444580078
aF167.89312744140625
aF162.87413024902344
aF158.1301727294922
aF156.5787353515625
aF153.78724670410156
aF148.49844360351562
aF149.27806091308594
aF148.2250213623047
aF142.85972595214844
aF142.2891082763672
aF140.09642028808594
aF139.3138427734375
aF150.2032470703125
aF138.85000610351562
aF136.10816955566406
aF144.9215545654297
aF141.19064331054688
aF134.8312530517578
aF135.68051147460938
aF139.38232421875
aF137.6932830810547
as.