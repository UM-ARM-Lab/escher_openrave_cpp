(dp0
S'training_loss'
p1
(lp2
F497.6833801269531
aF226.51600646972656
aF175.53199768066406
aF167.61610412597656
aF153.4329071044922
aF157.52011108398438
aF148.31320190429688
aF137.5942840576172
aF135.35263061523438
aF132.69638061523438
aF126.84515380859375
aF112.59320068359375
aF96.65201568603516
aF100.84807586669922
aF93.93116760253906
aF81.62600708007812
aF79.60520935058594
aF78.17681884765625
aF80.52898406982422
aF83.30847930908203
aF67.25621032714844
aF60.392677307128906
aF59.338478088378906
aF55.63292694091797
aF55.05387496948242
aF54.246299743652344
aF50.7807731628418
aF50.4119758605957
aF47.423194885253906
aF48.20335388183594
aF45.87948226928711
aF41.43161392211914
aF39.91629409790039
aF45.68802261352539
aF40.26535415649414
aF46.014991760253906
aF47.086395263671875
aF35.67878341674805
aF45.950531005859375
aF34.256587982177734
aF33.64705276489258
asS'validation_loss'
p3
(lp4
F481.9119873046875
aF225.4846954345703
aF168.4906768798828
aF162.90524291992188
aF151.30738830566406
aF158.33192443847656
aF156.04176330566406
aF147.99530029296875
aF149.1619873046875
aF151.96420288085938
aF150.68495178222656
aF140.3409881591797
aF135.26089477539062
aF141.9996337890625
aF132.94989013671875
aF130.82069396972656
aF126.94371795654297
aF129.82228088378906
aF129.58651733398438
aF132.02340698242188
aF127.85954284667969
aF120.3379135131836
aF122.44831848144531
aF121.36387634277344
aF123.26241302490234
aF121.52307891845703
aF122.6189193725586
aF121.5959701538086
aF119.64488220214844
aF121.13422393798828
aF120.2291259765625
aF120.26201629638672
aF119.64861297607422
aF119.17082977294922
aF119.28398132324219
aF121.08275604248047
aF123.4539794921875
aF119.85208892822266
aF123.01753234863281
aF119.6600570678711
aF118.28922271728516
as.