(dp0
S'training_loss'
p1
(lp2
F497.8572998046875
aF181.01344299316406
aF193.3855438232422
aF184.1948699951172
aF164.89010620117188
aF155.3109588623047
aF155.4191436767578
aF169.46041870117188
aF149.7393035888672
aF151.07119750976562
aF145.496826171875
aF145.9678192138672
aF159.18641662597656
aF141.8677520751953
aF142.56788635253906
aF167.1091766357422
aF147.5709991455078
aF137.7789764404297
aF138.04197692871094
aF136.7439727783203
aF134.00912475585938
aF131.8782958984375
aF130.31222534179688
aF126.87471008300781
aF123.91815185546875
aF129.38601684570312
aF120.45182800292969
aF118.3582763671875
aF116.80686950683594
aF117.20580291748047
aF125.34161376953125
asS'validation_loss'
p3
(lp4
F482.0869445800781
aF174.4374237060547
aF191.38690185546875
aF176.31900024414062
aF157.21499633789062
aF146.96139526367188
aF147.50762939453125
aF164.50357055664062
aF142.23326110839844
aF145.71986389160156
aF140.83010864257812
aF141.06419372558594
aF156.31019592285156
aF139.82916259765625
aF142.25062561035156
aF163.91815185546875
aF148.87071228027344
aF143.38099670410156
aF143.78408813476562
aF143.8530731201172
aF142.52621459960938
aF144.95582580566406
aF143.77667236328125
aF144.584228515625
aF149.9495086669922
aF150.5472412109375
aF146.98367309570312
aF147.7960968017578
aF150.75552368164062
aF148.8959503173828
aF154.23403930664062
as.