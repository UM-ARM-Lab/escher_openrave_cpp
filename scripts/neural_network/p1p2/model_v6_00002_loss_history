(dp0
S'training_loss'
p1
(lp2
F497.8135070800781
aF173.34095764160156
aF149.06887817382812
aF134.7385711669922
aF133.47122192382812
aF115.55671691894531
aF109.8738021850586
aF110.02503967285156
aF98.76203918457031
aF96.19937896728516
aF91.58966064453125
aF89.05689239501953
aF89.72502899169922
aF81.55752563476562
aF78.3929214477539
aF77.65799713134766
aF75.91120910644531
aF72.8205337524414
aF72.7630615234375
aF71.97607421875
aF68.05535888671875
aF70.18888092041016
aF65.66307067871094
aF65.26927947998047
aF64.9867935180664
aF64.52555084228516
aF61.80117416381836
aF59.0897102355957
aF58.250221252441406
aF59.887351989746094
aF60.1079216003418
aF55.875648498535156
aF57.30855178833008
aF53.666053771972656
aF69.62847137451172
aF63.297813415527344
aF58.940284729003906
aF60.088844299316406
aF62.31764221191406
aF55.18179702758789
aF57.88071060180664
asS'validation_loss'
p3
(lp4
F482.042724609375
aF173.86550903320312
aF152.02273559570312
aF146.17271423339844
aF145.90248107910156
aF133.60374450683594
aF134.5481719970703
aF135.45208740234375
aF128.7236328125
aF134.47584533691406
aF133.89492797851562
aF130.9848175048828
aF129.06582641601562
aF127.39746856689453
aF124.13806915283203
aF127.0044174194336
aF124.19368743896484
aF123.49810028076172
aF123.5087661743164
aF123.1014175415039
aF122.28441619873047
aF121.43507385253906
aF121.09716796875
aF121.70680236816406
aF120.43301391601562
aF120.43828582763672
aF119.26459503173828
aF120.28846740722656
aF119.95516967773438
aF118.36550903320312
aF118.51969909667969
aF118.48211669921875
aF121.8092269897461
aF119.80455780029297
aF124.78858184814453
aF121.2155990600586
aF120.833251953125
aF119.02330780029297
aF120.56172180175781
aF120.71728515625
aF119.64122009277344
as.